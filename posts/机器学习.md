---
tags:
  - ML
  - 机器学习
  - 深度学习
  - 神经网络
  - AI
status: publish
date created: 2024-07-18 09:52:53
date modified: 2025-08-04 23:01:33
---
机器学习在干什么：寻找一个==函数==

机器学习的训练
- 写出带有未知量的模型函数
- 定义损失函数
- 优化：逼近需要的函数

==线性函数只能是线性的，无法逼近复杂的函数，所以存在较大的模型偏差==，但是如果使用分段线性函数，并且分段足够多，就能逼近任何一个函数

这种类线性函数，统称为激活函数，我们可以使用 Sigmoid 函数，或者 ReLU 函数  
通过改变参数的值，可以调整激活函数的伸缩变化
$$
sigmoid=\frac{1}{1+e^{-(b+wx)}}
$$
$$ReLU=max\left( 0,b+wx \right)$$

我们将特征进行加权求和之后，经过多个激活函数得到的结果进行加权求和，得到新的预测值

因此，我们定义新的模型函数
$$
y=b+\sum_{i}\left (c_{i}+sigmoid\left( b_{i}+\sum_{j}w_{ij}x_{j} \right)\right)
$$

我们可以用矩阵和向量来简写上述模型
$$
y=b+c^{T}\sigma(\mathbf{b}+\mathbf{W}\mathbf{x})
$$

将需要训练的参数向量展开放在一个新的向量 $\boldsymbol{\theta}$ 中，我们新的优化方式就变成了求 $\boldsymbol{\theta}^{*}=arg\min_{\boldsymbol{\theta}}L$

在实际训练中，我们会将 N 维的特征随机分成若干 batch，每次 Batch 进行一次 $\boldsymbol{\theta}$ 的 update，所有 batch 都进行了一次叫做一个 epoch

## 反向传播

参数的训练方法，叫做 Gradient Descent
先求梯度
$$
\mathbf{g}=\begin{bmatrix} 
\end{bmatrix}
$$

---

# Terminology

*[训练]: Traning  
*[损失函数]: Loss Function  
*[优化]: Optimization  
*[模型偏差]: Model Bias  
*[机器学习]: Machine Learning  
*[线性函数]: Linear Function  
*[Activation Function]: 激活函数  
*[feature]: 特征  
*[批次]: batch

